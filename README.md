# OCCLUSION SIMULATOR FOR TRAJECTORY DATASETS
This repository contains the code for a simulator, that is capable of generating *spatio-temporally defined occlusions* from trajectory data that is widely available within the trajectory prediction research field.

Our simulator generates occlusion cases from agents' trajectories, focusing on generating cases for which the agents are *currently occluded*.

We provide the code for our simulator, as well as the necessary functionalities for its operation on the [Stanford Drone Dataset](https://cvgl.stanford.edu/projects/uav_data/).

## Installation / Setup
### Environment

*We recommend to use Anaconda to host the project's environment: the project relies on the [scikit-geometry](https://github.com/scikit-geometry/scikit-geometry) library, which is only directly accessible from the conda-forge channel (otherwise, it can be built from source, with [CGAL 5.0](https://www.cgal.org/) installed).
Though installation through other methods might be possible, only the following instructions have been verified to work properly.*

1. Create the environment:
   ```
   conda create -n <environment-name> python=3.8 pip
   ```
   Replace `<environment-name>` with the name of your environment.
2. Activate the environment:
    ```
    conda activate <environment-name>
    ```
3. Install [PyTorch 1.8.0](https://pytorch.org/get-started/previous-versions/#v180) with the appropriate CUDA version.
4. Install scikit-geometry:
   ```
   conda install -c conda-forge scikit-geometry
   ```
5. Install the remaining dependencies:
   ```
   pip install -r requirements.txt
   ```
Once the environment installation process is complete, simply activate the environment:
```
conda activate <environment-name>
```

### Stanford Drone Dataset

1. Download the [Stanford Drone Dataset](https://cvgl.stanford.edu/projects/uav_data/) and extract its contents anywhere on your system.
2. Inside the [config/sdd_dataset_config.yaml](config/sdd_dataset_config.yaml) file, fill the `path` entry with the root directory of your extracted Stanford Drone Dataset (i.e., the directory where the dataset's README and the annotation directory are located).

### Environment Variables

1. Add the directory containing this README.md file to the PYTHONPATH environment variable:
   ```
   export PYTHONPATH=$PWD
   ```
   
### Coordinates Conversion File

1. Create the coordinates conversion `.txt` file inside the [config](config) directory by running the [src/data/save_coord_conv_file.py](src/data/save_coord_conv_file.py) script:
   ```
   python src/data/save_coord_conv_file.py
   ```

## Dataset Processing

### Preprocessing

Before running the simulator, the dataset must first be preprocessed (the preprocessing involves subsampling of measurements to a desired frequency, removal of undesirable trajectories and selection of desired agent classes).
The preprocessing of the dataset can be parametrized using the [config/dataset_preprocessing_config.yaml](config/dataset_preprocessing_config.yaml) file. Feel free to adapt the parameters to your liking. When ready, you can run the preprocessing of the dataset by running the [src/data/dataset_saving.py](src/data/dataset_saving.py) script, with the following command:
```
python src/data/dataset_saving.py --dir-name <dataset_name>
```
This will create a directory `outputs/pickled_dataloaders/<dataset_name>`, where the preprocessed dataset will be stored.

In order to allow the code to interface with the newly created dataset properly, fill the `pickle_id` field of the [config/dataset_config.yaml](config/dataset_config.yaml) file with the dataset name you chose, `<dataset_name>`.

### Occlusion Simulation

Once the preprocessed dataset has been generated, the occlusion simulator can be run.
Configure the simulator by modifying (or copying) the [config/occlusion_simulator_config.yaml](config/occlusion_simulator_config.yaml) file to your liking.
Once you're ready to run the simulator, simply run the [src/occlusion_simulation/simple_occlusion.py](src/occlusion_simulation/simple_occlusion.py) script, with the following command.

```
python src/occlusion_simulation/simple_occlusion.py --simulator-cfg config/occlusion_simulator_config.yaml
```

The `--simulator-cfg` flag lets you refer to any configuration file (containing the same fields as the [config/occlusion_simulator_config.yaml](config/occlusion_simulator_config.yaml) file).
The simulation process can take a while.
When it is complete, a new directory will be present under the [outputs/pickled_dataloaders/<dataset_name>](outputs/pickled_dataloaders/<dataset_name>) directory, containing all the occlusion data generated by the simulation process (the directory's name is the `sim_id` field of the occlusion simulator configuration file).

## Dataset Usage

### Dataset Classes

The dataset files generated by our preprocessing and occlusion simulation processes can be used to instantiate PyTorch Dataset objects, implemented inside the [src/data/sdd_dataloader.py](src/data/sdd_dataloader.py) file.
Dataset objects are instantiated with the configuration parameters present inside the [config/dataset_config.yaml](config/dataset_config.yaml) file (or a copy of this file, with identical fields).
You can view random instances retrieved from those dataset objects by running the [src/visualization/visualize_dataset_instances.py](src/visualization/visualize_dataset_instances.py) script, with the following command:

```
python src/visualization/visualize_dataset_instances.py --cfg config/dataset_config.yaml --dataset-class base
```

the `--dataset-class base` option instructs the script to instantiate the preprocessed dataset, without occlusions.
Instead, you may pass `sim` to this option to instantiate a Dataset object with the data contained in the occlusion simulation directories mentioned within the `sim_ids` field of the dataset configuration file.
